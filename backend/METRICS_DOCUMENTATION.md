# Metrik Hesaplama FonksiyonlarÄ± DokÃ¼mantasyonu

## ğŸ“Š Ä°ncelenecek Parametreler ve Metrikler

Proje kapsamÄ±nda araÃ§larÄ±n yetkinliklerini Ã¶lÃ§mek iÃ§in Ã§ok boyutlu bir deÄŸerlendirme matrisi kullanÄ±lmaktadÄ±r.

### 1. Hata Tespit BaÅŸarÄ±sÄ± (Defect Detection Accuracy)

**AÃ§Ä±klama:** AraÃ§larÄ±n mevcut hatalarÄ± tespit etme oranÄ±; precision ve recall metrikleri kullanÄ±larak hesaplanÄ±r.

**Hesaplama:**
- **Precision (DoÄŸruluk):** `TP / (TP + FP)`
  - DoÄŸru pozitif / (DoÄŸru pozitif + YanlÄ±ÅŸ pozitif)
  - Bulunan issue'larÄ±n ne kadarÄ±nÄ±n gerÃ§ekten hata olduÄŸunu gÃ¶sterir
  
- **Recall (Geri Ã‡aÄŸÄ±rma):** `TP / (TP + FN)`
  - DoÄŸru pozitif / (DoÄŸru pozitif + YanlÄ±ÅŸ negatif)
  - GerÃ§ek hatalarÄ±n ne kadarÄ±nÄ±n bulunduÄŸunu gÃ¶sterir
  
- **F1 Score:** `2 * (precision * recall) / (precision + recall)`
  - Precision ve recall'un harmonik ortalamasÄ±
  - Dengeli bir performans Ã¶lÃ§Ã¼sÃ¼

**KullanÄ±m:**
```python
from metrics.advanced_metrics import AdvancedMetricsCalculator

calculator = AdvancedMetricsCalculator()
accuracy = calculator.calculate_defect_detection_accuracy(
    detected_issues=detected_issues,  # AraÃ§ tarafÄ±ndan bulunan issue'lar
    ground_truth=ground_truth         # GerÃ§ekte var olan issue'lar
)

print(f"Precision: {accuracy['precision']:.2%}")
print(f"Recall: {accuracy['recall']:.2%}")
print(f"F1 Score: {accuracy['f1_score']:.2%}")
```

---

### 2. Kod Kapsama OranÄ± (Code Coverage)

**AÃ§Ä±klama:** Yapay zeka tarafÄ±ndan oluÅŸturulan test senaryolarÄ±nÄ±n hedef yazÄ±lÄ±mÄ±n mantÄ±ksal yollarÄ±nÄ± ve kod satÄ±rlarÄ±nÄ± ne Ã¶lÃ§Ã¼de kapsadÄ±ÄŸÄ±.

**Hesaplama:**
- **Code Coverage:** `(Analiz edilen satÄ±rlar / Toplam satÄ±rlar) * 100`
- **Files Analyzed:** Analiz edilen dosya sayÄ±sÄ±
- **Lines Analyzed:** Analiz edilen satÄ±r sayÄ±sÄ±

**KullanÄ±m:**
```python
coverage = calculator.calculate_code_coverage(
    raw_data=raw_data,      # AraÃ§tan gelen ham veri
    total_lines=1000,       # Toplam kod satÄ±rÄ± sayÄ±sÄ±
    total_files=50          # Toplam dosya sayÄ±sÄ±
)

print(f"Code Coverage: {coverage['code_coverage']:.2f}%")
print(f"Files Analyzed: {coverage['files_analyzed']}")
```

---

### 3. Kod Kalitesi ve Standart Uyumu

**AÃ§Ä±klama:** OluÅŸturulan test kodlarÄ±nÄ±n ve dÃ¼zeltme Ã¶nerilerinin okunabilirlik, bakÄ±m yapÄ±labilirlik ve endÃ¼stri standartlarÄ±na (Ã¶rn. Clean Code prensipleri) uygunluÄŸu analiz edilir.

**Not:** Bu metrik genellikle manuel deÄŸerlendirme veya ek analiz araÃ§larÄ± gerektirir.

**DeÄŸerlendirme Kriterleri:**
- Kod okunabilirliÄŸi
- BakÄ±m yapÄ±labilirlik
- Clean Code prensipleri uyumu
- EndÃ¼stri standartlarÄ±na uygunluk

---

### 4. YanlÄ±ÅŸ Alarm EÄŸilimi (False Positive Rate)

**AÃ§Ä±klama:** AraÃ§larÄ±n hatasÄ±z kod bloklarÄ±nÄ± yanlÄ±ÅŸlÄ±kla hatalÄ± olarak raporlama sÄ±klÄ±ÄŸÄ±.

**Hesaplama:**
- **False Positive Rate:** `FP / (FP + TN)` veya `FP / Total Detected`
  - YanlÄ±ÅŸ pozitif / (YanlÄ±ÅŸ pozitif + DoÄŸru negatif)
  - Bulunan issue'larÄ±n ne kadarÄ±nÄ±n yanlÄ±ÅŸ alarm olduÄŸunu gÃ¶sterir

**KullanÄ±m:**
```python
accuracy = calculator.calculate_defect_detection_accuracy(
    detected_issues=detected_issues,
    ground_truth=ground_truth
)

print(f"False Positive Rate: {accuracy['false_positive_rate']:.2%}")
print(f"False Positives: {accuracy['false_positives']}")
```

---

### 5. Operasyonel Verimlilik

**AÃ§Ä±klama:** AracÄ±n analiz ve Ã§Ä±ktÄ± Ã¼retme sÃ¼recini "Ortalama Ã‡alÄ±ÅŸma SÃ¼resi" ve kaynak kullanÄ±mÄ± (CPU/Bellek) Ã¼zerinden nicelleÅŸtirir.

**Hesaplama:**
- **Average Scan Time:** Ortalama tarama sÃ¼resi (saniye)
- **CPU Usage Percent:** CPU kullanÄ±m yÃ¼zdesi
- **Memory Usage MB:** Bellek kullanÄ±mÄ± (MB)

**KullanÄ±m:**
```python
efficiency = calculator.calculate_operational_efficiency()

print(f"Average Scan Time: {efficiency['average_scan_time']:.2f}s")
print(f"CPU Usage: {efficiency['cpu_usage_percent']:.2f}%")
print(f"Memory Usage: {efficiency['memory_usage_mb']:.2f} MB")
```

---

## ğŸ”§ TÃ¼m Metrikleri Hesaplama

```python
from metrics.advanced_metrics import AdvancedMetricsCalculator

calculator = AdvancedMetricsCalculator()

# TÃ¼m metrikleri hesapla
result = calculator.calculate_all_advanced_metrics(
    raw_data=raw_data,              # AraÃ§tan gelen ham veri
    detected_issues=detected_issues, # Bulunan issue'lar
    ground_truth=ground_truth,      # GerÃ§ek issue'lar (opsiyonel)
    scan_duration=12.5,              # Tarama sÃ¼resi
    total_lines=1000,                # Toplam satÄ±r sayÄ±sÄ±
    total_files=50                   # Toplam dosya sayÄ±sÄ±
)

# SonuÃ§larÄ± kullan
print(f"Precision: {result.precision:.2%}")
print(f"Recall: {result.recall:.2%}")
print(f"F1 Score: {result.f1_score:.2%}")
print(f"Code Coverage: {result.code_coverage:.2f}%")
print(f"False Positive Rate: {result.false_positive_rate:.2%}")
print(f"Average Scan Time: {result.average_scan_time:.2f}s")
```

---

## ğŸ“ Ground Truth Verisi

**Ã–nemli:** Precision ve Recall hesaplamak iÃ§in "ground truth" (gerÃ§ek hata listesi) gereklidir.

### Ground Truth FormatÄ±

```python
ground_truth = [
    {
        "file": "app.py",
        "line": 18,
        "type": "SQL_INJECTION",
        "severity": "high"
    },
    {
        "file": "app.py",
        "line": 32,
        "type": "COMMAND_INJECTION",
        "severity": "high"
    }
]
```

### Ground Truth OluÅŸturma

1. **Manuel Olarak:** Test projelerindeki bilinen hatalarÄ± listeleyin
2. **Test Projelerinden:** `vulnerable_demo` gibi kasÄ±tlÄ± hata iÃ§eren projelerden
3. **Uzman DeÄŸerlendirmesi:** Kod incelemesi yaparak gerÃ§ek hatalarÄ± belirleyin

---

## ğŸ¯ KullanÄ±m SenaryolarÄ±

### Senaryo 1: Snyk vs DeepSource KarÅŸÄ±laÅŸtÄ±rmasÄ±

```python
# Her iki araÃ§ iÃ§in metrikleri hesapla
snyk_metrics = calculator.calculate_all_advanced_metrics(
    raw_data=snyk_raw_data,
    detected_issues=snyk_issues,
    ground_truth=ground_truth,
    scan_duration=snyk_duration
)

deepsource_metrics = calculator.calculate_all_advanced_metrics(
    raw_data=deepsource_raw_data,
    detected_issues=deepsource_issues,
    ground_truth=ground_truth,
    scan_duration=deepsource_duration
)

# KarÅŸÄ±laÅŸtÄ±r
print(f"Snyk Precision: {snyk_metrics.precision:.2%}")
print(f"DeepSource Precision: {deepsource_metrics.precision:.2%}")
```

### Senaryo 2: Benchmark Raporu OluÅŸturma

```python
# TÃ¼m projeler iÃ§in metrikleri topla
results = []
for project in ["flask_demo", "vulnerable_demo"]:
    metrics = calculate_metrics_for_project(project)
    results.append(metrics)

# Rapor oluÅŸtur
generate_benchmark_report(results)
```

---

## ğŸ“š Ä°lgili Dosyalar

- `backend/metrics/advanced_metrics.py` - GeliÅŸmiÅŸ metrik hesaplama sÄ±nÄ±flarÄ±
- `backend/metrics/base_metric.py` - Base metric sÄ±nÄ±fÄ±
- `backend/metrics/result_model.py` - Temel metrik modeli
- `backend/metrics/snyk_metrics.py` - Snyk metrik implementasyonu
- `backend/metrics/deepsource_metrics.py` - DeepSource metrik implementasyonu

